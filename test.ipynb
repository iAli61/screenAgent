{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e511724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ea3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Endpoint: https://aoai-sweden-505.openai.azure.com/\n",
      "Azure API Key available: Yes\n",
      "Azure API Version: 2025-03-01-preview\n",
      "Model deployment name: gpt-4o\n",
      "Endpoint URL: https://aoai-sweden-505.openai.azure.com//openai/deployments/gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAI configuration\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_version = os.getenv(\"OPENAI_API_VERSION\", \"2023-07-01-preview\")\n",
    "model = os.getenv(\"LLM_MODEL\", \"gpt-35-turbo\")\n",
    "\n",
    "print(f\"Azure Endpoint: {azure_endpoint}\")\n",
    "print(f\"Azure API Key available: {'Yes' if azure_api_key else 'No'}\")\n",
    "print(f\"Azure API Version: {azure_api_version}\")\n",
    "print(f\"Model deployment name: {model}\")\n",
    "\n",
    "# Initialize Azure OpenAI client if enabled\n",
    "\n",
    "# Create endpoint URL with deployment name\n",
    "endpoint_url = f\"{azure_endpoint}/openai/deployments/{model}\"\n",
    "print(f\"Endpoint URL: {endpoint_url}\")\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint_url,\n",
    "    credential=AzureKeyCredential(azure_api_key),\n",
    "    api_version=azure_api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129d4ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The Eiffel Tower is often considered a must-see attraction for a variety of reasons:\n",
      "\n",
      "1. **Architectural Marvel**: Designed by Gustave Eiffel for the 1889 World's Fair, the tower was initially met with skepticism but quickly became an architectural triumph. Its iconic iron lattice design is both unique and aesthetically striking.\n",
      "\n",
      "2. **Panoramic Views**: Standing at 324 meters (1,063 feet), the Eiffel Tower offers spectacular panoramic views of Paris. Visitors can ascend to various levels, including an observatory deck at the top, to enjoy breathtaking vistas of the city's landmarks and landscape.\n",
      "\n",
      "3. **Symbol of Paris**: The Eiffel Tower has become synonymous with Paris itself. Its silhouette is instantly recognizable and is often used to represent the city in art, media, and popular culture.\n",
      "\n",
      "4. **Historical Significance**: At the time of its completion, the Eiffel Tower was the tallest man-made structure in the world, holding that title for over 40 years. Its construction showcased the innovative engineering and artistic prowess of the late 19th century.\n",
      "\n",
      "5. **Cultural Experience**: Visiting the Eiffel Tower is a cultural experience, with bustling activity around the base, including street performers and souvenir shops. The tower is beautifully illuminated at night, making it a romantic and picturesque sight.\n",
      "\n",
      "6. **Versatile Venue**: The Eiffel Tower hosts various events and activities, from dining in its restaurants to special exhibitions. Seasonal events, like New Year celebrations and the Bastille Day fireworks, often feature the tower prominently.\n",
      "\n",
      "Overall, the Eiffel Tower is celebrated not only for its aesthetic and engineering achievements but also for its cultural and historical significance to Paris and the world.\n",
      "Model: gpt-4o-2024-08-06\n",
      "Usage:\n",
      "\tPrompt tokens: 202\n",
      "\tTotal tokens: 539\n",
      "\tCompletion tokens: 337\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I am going to Paris, what should I see?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\\n\\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\\n\\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is so great about #1?\"\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 2048\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"Usage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e292c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Endpoint: https://aoai-sweden-505.openai.azure.com/\n",
      "Azure API Key available: Yes\n",
      "Azure API Version: 2025-03-01-preview\n",
      "Model deployment name: gpt-4o\n",
      "Endpoint URL: https://aoai-sweden-505.openai.azure.com//openai/deployments/gpt-4o\n",
      "Response: The image appears to show a portion of text from a code editor or integrated development environment (IDE) with syntax highlighting. The text includes the word \"settings\" and a partial sentence referencing \"UM_ENABLED\" and \"UM anal\". The different colors of the text indicate syntax elements like keywords, comments, or variable names. The dark background is typical for code editors, designed to reduce eye strain.\n",
      "Model: gpt-4o-2024-08-06\n",
      "Usage:\n",
      "\tPrompt tokens: 287\n",
      "\tTotal tokens: 366\n",
      "\tCompletion tokens: 79\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_version = os.getenv(\"OPENAI_API_VERSION\", \"2023-07-01-preview\")\n",
    "model = os.getenv(\"LLM_MODEL\", \"gpt-35-turbo\")\n",
    "\n",
    "print(f\"Azure Endpoint: {azure_endpoint}\")\n",
    "print(f\"Azure API Key available: {'Yes' if azure_api_key else 'No'}\")\n",
    "print(f\"Azure API Version: {azure_api_version}\")\n",
    "print(f\"Model deployment name: {model}\")\n",
    "\n",
    "# Initialize Azure OpenAI client if enabled\n",
    "\n",
    "# Create endpoint URL with deployment name\n",
    "endpoint_url = f\"{azure_endpoint}/openai/deployments/{model}\"\n",
    "print(f\"Endpoint URL: {endpoint_url}\")\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint_url,\n",
    "    credential=AzureKeyCredential(azure_api_key),\n",
    "    api_version=azure_api_version\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_image(image_path: str) -> Optional[Image.Image]:\n",
    "    \"\"\"\n",
    "    Validate if the image is suitable for processing.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if image is valid, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode not in ('RGB', 'L'):\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            max_dimension = 2048\n",
    "            if img.width > max_dimension or img.height > max_dimension:\n",
    "                ratio = min(max_dimension / img.width, max_dimension / img.height)\n",
    "                new_size = (int(img.width * ratio), int(img.height * ratio))\n",
    "                img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            img_byte_arr = io.BytesIO()\n",
    "            img.save(img_byte_arr, format='PNG', quality=85)\n",
    "            img_byte_arr.seek(0)\n",
    "            \n",
    "            return Image.open(img_byte_arr)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image preprocessing failed for {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def encode_image(image_path: str) -> Optional[str]:\n",
    "    \"\"\"Encode image as base64 with proper validation and preprocessing.\"\"\"\n",
    "    try:\n",
    "        \n",
    "\n",
    "        processed_img = preprocess_image(image_path)\n",
    "        if processed_img is None:\n",
    "            return None\n",
    "\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        processed_img.save(img_byte_arr, format='PNG', quality=85)\n",
    "        img_byte_arr.seek(0)\n",
    "        base64_encoded = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "\n",
    "        try:\n",
    "            base64.b64decode(base64_encoded)\n",
    "            return base64_encoded\n",
    "        except Exception as e:\n",
    "            print(f\"Base64 validation failed for {image_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image encoding failed for {image_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "prompt = \"What is in this image?\"\n",
    "\n",
    "# Image file path\n",
    "IMAGE_PATH = 'temp_image.png'\n",
    "\n",
    "\n",
    "base64_image = encode_image(IMAGE_PATH)\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant that can analyze images and provide information about them.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2048\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"Usage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45763c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This image appears to be a screenshot of a piece of code or text from a coding environment or text editor. The text is formatted with syntax highlighting, which is common in programming. The visible text reads \"settings\" and part of a sentence, \"...UM_ENABLED to true to enable UM analy...\", suggesting it is likely part of configuration settings or code related to enabling a feature, possibly abbreviated as \"UM.\" The colors (green and other colors) indicate different types of syntax highlighting typically used to differentiate between various elements such as keywords, strings, and comments in programming code.\n",
      "Model: gpt-4o-2024-08-06\n",
      "Usage:\n",
      "\tPrompt tokens: 287\n",
      "\tTotal tokens: 401\n",
      "\tCompletion tokens: 114\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is in this image?\"\n",
    "\n",
    "# Image file path\n",
    "IMAGE_PATH = 'temp_image.png'\n",
    "\n",
    "\n",
    "base64_image = encode_image(IMAGE_PATH)\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant that can analyze images and provide information about them.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2048\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"Usage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df88367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems you've mentioned an image, but since I can't view images directly, could you describe it to me? I'd be happy to help analyze or provide information based on your description!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11fd78a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': '404', 'message': 'Resource not found'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Image file path\n",
    "IMAGE_PATH = 'temp_image.png'\n",
    "\n",
    "\n",
    "# Read the image as binary\n",
    "with open(IMAGE_PATH, \"rb\") as image_file:\n",
    "    image_data = image_file.read()\n",
    "\n",
    "# Request headers and payload\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {azure_api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Describe the image.\"},\n",
    "        {\"role\": \"user\", \"content\": image_data.decode(\"latin-1\")}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the request to Azure OpenAI\n",
    "response = requests.post(azure_endpoint, headers=headers, json=payload)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e6e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
